---

---

# Ch02. 모델 평가 및 선택

> | 발표자 | 방준혁 |
> | --- | --- |

## 2.1 경험 오차 및 과적합

머신러닝은 결국 목적에 맞는 $f$를 추정하는 것입니다. 그리고 추정한 $f$는 이미 가지고 있는 데이터가 아니라, 새로운 샘플 위에서 우수한 성능을 보여야 합니다.

모델이 train set에서 가지는 오차를 훈련 오차(training error), 새로운 샘플을 투입하였을 때 가지는 오차를 **일반화 오차(generalization error)**라고 합니다. 우리는 훈련 오차가 아닌 일반화 오차가 최대한 작은 모델을 만들어야 합니다.

underfitting은 모델이 너무 단순하거나 학습을 충분하지 못한 경우에 발생하는 경우로 비교적 해결하기 쉽습니다. 예를 들면 딥러닝에서는 층을 깊게 하거나 epoch를 늘리는 방식으로 해결할 수 있습니다.

반면 overfitting은 모델이 데이터의 세부적인 특성까지 과도하게 학습한 경우로, 굉장히 까다로운 문제입니다. 모델의 표현력을 높이기 위해서는 더 많은 특성을 학습해야하기 마련인데, 이 경우 필연적으로 overfitting 문제와 맞닥뜨리기 대문입니다. overfitting 문제를 완화하는 것이 핵심 과제 중 하나라고 말할 수 있습니다.

목적에 가장 적합한 알고리즘과 파라미터를 선택하는 것을 모델 선택(model selection) 문제라고 합니다. 당연히 기준은 얼마나 모델의 일반화 능력이 우수한가하는 것입니다. 하지만 우리는 일반화 오차는 새로운 샘플을 대상으로 하는 오차입니다. 때문에 학습 과정에서 일반화 오차를 직접 얻을 수 있는 방법은 없습니다. 그렇다면 어떻게 학습 과정에서 목적에 맞는 모델을 선택할 수 있을까요?

>  다시 한번 말하지만, 우리가 원하는 모델은 새로운 샘플 데이터를 대상으로 우수한 성능을 보여야 합니다.



## 2.2 평가 방법

우리는 일반화  오차를 직접 구할 수 없습니다. 때문에 test set을 따로 준비해두고, 이를 학습이 끝난 모델에 투입하여 테스트 오차(testing error)를 구합니다. 그리고 이 테스트 오차를 일반화 오차의 근사값으로 간주합니다. 이는 test set이 새로운 샘플과 동일한 분포를 나타낸다는 가정을 바탕으로 합니다.

이 때 주의해야할 점은 test set과 train set의 중복을 최대한 피하는 것입니다. 모델은 train set으로 학습을 하는데, 이 때 사용된 데이터가 다수 test set에 있는 상황은 시험 문제에 기출문제가 대다수 출제된 상황과 같습니다.

### 

### 2.2.1 홀드아웃(hold-out)

평소에 자주 접할 수 있는 홀드아웃 방법은 데이터 세트를 겹치지 않는 임의의 두 집합으로 나누는 방법입니다.

$$
D = S \cup T \\
S \cap T = \varnothing
$$

- D : dataset

- S : train set

- T : test set

train set과 test set을 나눌 때, 가능하면 데이터 분포가 비슷하게 나누는 것이 좋습니다. 층화표집(stratified sampling)에 해당하는데, 층화표집은 모집단을 몇 개의 계층으로 나누어 계층의 비율대로 표본을 추출하는 방법입니다.

![](/Users/jhbang/github/machine-learning-zhou_zhihua/images/ch02/2022-01-15-15-29-13-image.png)

train set과 test set의 비율을 정하는 것에는 trade-off가 존재합니다. train set의 비율을 높이면 우리가 평가하고 싶은 데이터셋 전체를 학습한 것에 가까워지지만 test set이 적으므로 평가 결과의 신뢰성이 훼손됩니다. 반면, train set의 비율을 낮추면 학습한 모델이 평가하고 싶은 데이터셋을 학습한 모델과 멀어집니다.

> 일반적으로 전체 데이터 세트에서 2/3 ~ 4/5 정도를 train set으로 이용합니다.





### 2.2.2 교차 검증(cross validation)

1. 데이터셋을 k개의 서로소 집합(disjoint set)으로 나눈다.
   
   - $D=D_1 \cup D_2 \cup \cdots \cup D_k, \ D_i \cap D_j=\varnothing, \  \forall  i,j(i \ne j)$
   
   - $D_i$ 는 층화추출

2. (k - 1) 개의 부분집합을 train set으로, 나머지 하나를 test set으로 사용

3. k가지 방법으로 나누어진 train set과 test set으로 k번의 훈련과 테스트 진행

4. k개의 테스트 결과 평균 계산

> 교차 검증법의 안정성과 정확도는 k값에 영향을 받는다. 이를 강조하기 위해 교차 검증을 k겹 교차 검증(k-fold cross validation)이라 부르기도 한다.
> k값은 주로 10으로 두며 이를 10-fold 교차 검증이라 한다.

샘플을 나누는 과정에서 생길 수 있는 차별을 줄이기 위해 k겹 교차 검증은 일반적으로 p번을 반복합니다. 주로 '10차 10겹 교차 검증'을 사용합니다. '10차 10겹 교차 검증은' 총 100번의 훈련과 테스트를 진행하게 됩니다.



k를 샘플의 수와 동일하게 두는 경우, LOOCV(Leave-One-Out Cross Validation)라고 부릅니다. LOOCV는 원본 데이터와 샘플의 수가 1개밖에 차이나지 않기 때문에 모델의 편향이 작다는 장점이 있습니다. 하지만 계산량이 많아진다는 단점이 있습니다.



### 2.2.3 부트스트래핑(bootstrapping)

부트스트래핑은 부트스트랩 샘플링(bootstrap sampliong)에 기반을 둔 샘플 추출법입니다. 원본 데이터셋 D가 m개의 샘플을 가지고 있다고 가정합시다. D에서 데이터를 m번 복원추출하여 만든 m개의 데이터셋 D'를 train set으로, D에서 D'를 제외한 부분을 test set으로 활용하는 것이 부트스트래핑입니다.



위 상황에서 원본 데이터셋의 특정 샘플이 새로운 데이터셋에 포함되지 않을 확률은 다음과 같습니다.

$$
\lim_{m \to \infty}(1 - {1 \over m})^m = \frac{1}{e} \approx0.368
$$





부트스트래핑은 데이터 수가 적거나, train/test set으로 분류하기 어려운 경우 효과적입니다. 하지만 부트스트래핑을 통해 생성된 데이터셋은 초기 데이터의 분포와 다를 수 있기 때문에 학습 과정에서 모델의 편향이 커질 수 있습니다. 때문에 데이터 수가 충분하다면 일반적으로 hold-out 기법이나 cross validation 기법을 더 자주 이용합니다.





### 2.2.4 파라미터 튜닝과 최종 모델

알고리즘을 선택하는 것뿐만 아니라, 파라미터를 적합한 값으로 설정하는 것 역시 모델의 최종 성능에 큰 영향을 미칩니다.

우리는 모델 평가 및 선택 과정에서 **검증 세트(validation set)**를 이용할 수 있습니다. validation set은 모델 선택과 파라미터 조율을 위해 사용합니다. 모델의 최종 성능을 평가하기 위한 test set과의 차이점은, validation set은 학습에 참여한다는 것입니다. 우리는 validation set의 평가 결과를 바탕으로 학습 과정에서 만들어지는 다양한 모델 중 우수한(우수하다고 생각되는) 모델을 선택할 수 있습니다.



## 2.3 모델 성능 측정

혼동행렬(confusion matrix)

정밀도(precision)

재현율(recall)

TP : true positive

FP : false positive

TN : true negative

FN : false negative



## 2.4 비교 검증

test set에 대한 성능 $\ne$ 일반화 성능







## 2.5 편향과 분산

![](/Users/jhbang/github/machine-learning-zhou_zhihua/images/ch02/2022-01-16-19-55-16-image.png)
