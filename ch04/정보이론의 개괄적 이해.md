# 정보이론

**역사**

- 클로드 새넌 from A symbolic Analysis of Relay and Switching Circuits(1937) 
  
  - 모든 회로는 일련의 방정식과 방정식의 조건으로 기술된다 
  
  - 방정식을 푸는 계산법은 명제의 계산법과 정확히 일치한다 
  
  - 회로는 방정식에서 즉시 도출될 수 있다. 
  
  - => 전기 회로로 모든 논리 연산이 가능하다면, 기계는 인간의 합리적 논리를 따라올 수 있다.

- Alan Turing : 모든 해결 가능한 수학 문제는 기계로 해결할 수 있음을 보임 

=> 클로드 새넌과 알랜 튜링의 개념이 합쳐져 컴퓨터의 기원이 됨. 

### 

### 정보의 정의

- 우리가 극복하는 불확실성. 불확실성이 큰(잘 발생하지 않는) 정보일 수록 우리에겐 더욱 가치가 있음. 

> - 정보는 동일한 사건도 배경에 따라 의미가 달라질 수 있다. 따라서 각 상황에 따라 확률값으로 접근해야 함. 
>   
>   - 경우의 수가 적다 = 정보의 양이 적다.
> 
> - 또한 우리가 사용하는 정보에 잉여성이 있음. 
>   
>   - ex) "나는 사과를 좋아합" 의 문구가 나오면, 뒤에 붙을 말이 무엇인지 유추할 수 있음. 즉, 뒤의 정보가 없어도 의미를 충분히 전달할 '잉여'를 가지고 있음. 

>  즉, 정보 이론에서는 대표적인 데이터(대표성)를 가지는 것보단, 지금까지 얻지못했던 데이터를 얻는 데(희소성)에 높은 값을 부여하는 것.  



### 통신의 수학적 이론(1948)

- **데이터 압축**
  
  - 가장 빈도가 높은 경우에 가장 짧은 비트를 할당함. 이때 평균 비트 길이를 줄일 수 있다(압축할 수 있다)
  - **정보 엔트로피(새넌 엔트로피) : 각 메시지에 포함된 정보의 기댓값(평균)**
  - > 정보 엔트로피 = $\sum_{i=1}^{n} -P *$ $\log_2 P$
    > - 정보량 = $-\log_2 P$ = $\log_2 $  $\frac {1}{P}$ , *P* = 확률
    >   
    >   - 조건 1) 불확실성이 클수록 정보량이 커진다.
    >     
    >     - Why? 잘 안 일어나지 않은 상황일수록 새롭게 얻는 데이터들이 많기 때문 
    >   
    >   - 조건 2) 두 개의 독립된 정보가 있을 경우, 두 경우 모두의 정보량은 각각을 더한 것과 같아야 한다. 
    >     
    >     Q. 정보량은 총 몇개의 비트로 정보를 표현할 수 있는가를 의미..?.
  - >  메시지에 잉여성을 더하면 오류를 줄일 수 있으며, 제한 속도 내에서는 원하는 만큼 정확한 메시지를 보낼 수 있다는 점을 증명함

- 

- => 정보 이론의 기초 토대 형성  및 정보 혁명 시작 

참고 

1. [천재 수학자가 밝혀낸 ‘정보’의 비밀 | 10분만에 정보 이론 이해하기 - YouTube](https://www.youtube.com/watch?v=d3iyDP3_AjU)

2. [정보량과 불확실성의 상관관계 (섀넌 엔트로피) - YouTube](https://www.youtube.com/watch?v=CdH7U3IjRI8)

3. [정보 이론: Information Theory 1편 (brunch.co.kr)](https://brunch.co.kr/@chris-song/68)
